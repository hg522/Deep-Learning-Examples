{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federer Vs Djokovic Image Classification using Deep Learning with Spark and Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "   .master(\"local[*]\") \\\n",
    "   .appName(\"ImageClassification\") \\\n",
    "   .config(\"spark.executor.memory\", \"16gb\") \\\n",
    "   .config(\"spark.driver.memory\", \"16G\") \\\n",
    "   .config(\"spark.driver.offHeap.enabled\", \"true\") \\\n",
    "   .config(\"spark.driver.offHeap.size\", \"16G\") \\\n",
    "   .config(\"spark.executor.maxResultSize\", \"16gb\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## .config(\"spark.memory.offHeap.enabled\",true)\n",
    "###     .config(\"spark.memory.offHeap.size\",\"16g\")  \n",
    "### --executor-memory 64G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preetham/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/preetham/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import sparkdl as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images of Djokovic and Federer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDjokovic = dl.readImages('./tennis/small/djokovic/').withColumn('label', f.lit(0))\n",
    "dfFederer = dl.readImages('./tennis/small/federer/').withColumn('label', f.lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfDjokovic.show(n=10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFederer.show(n=10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDFdjokovic, testDFdjokovic = dfDjokovic.randomSplit([80.00, 20.00], seed =12)\n",
    "trainDFfederer, testDFfederer = dfFederer.randomSplit([80.00, 20.00], seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in trainDFdjokovic is 48\n",
      "The number of images in testDFdjokovic is 12\n",
      "The number of images in trainDFfederer is 48\n",
      "The number of images in testDFfederer is 12\n"
     ]
    }
   ],
   "source": [
    "print('The number of images in trainDFdjokovic is {}'.format(trainDFdjokovic.toPandas().shape[0]))\n",
    "print('The number of images in testDFdjokovic is {}'.format(testDFdjokovic.toPandas().shape[0]))\n",
    "print('The number of images in trainDFfederer is {}'.format(trainDFfederer.toPandas().shape[0]))\n",
    "print('The number of images in testDFfederer is {}'.format(testDFfederer.toPandas().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDFdjokovic.unionAll(trainDFfederer)\n",
    "testDF = testDFdjokovic.unionAll(testDFfederer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in the training data is 96\n",
      "The number of images in the testing  data is 24\n"
     ]
    }
   ],
   "source": [
    "print('The number of images in the training data is {}' .format(trainDF.toPandas().shape[0]))\n",
    "print('The number of images in the testing  data is {}' .format(testDF.toPandas().shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Deep Image Featurizer + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "## Xception InceptionV3\n",
    "vectorizer = dl.DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName='InceptionV3')\n",
    "logreg = LogisticRegression(maxIter=30,regParam=0.05, elasticNetParam=0.3, labelCol = \"label\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[vectorizer, logreg])\n",
    "\n",
    "pipeline_model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_4000a4eb4bc5f8674dba\n"
     ]
    }
   ],
   "source": [
    "lrModel = pipeline_model\n",
    "print(lrModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.stages[1].write().overwrite().save('lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n",
      "Logistic Regression Model: Test set accuracy = 0.625\n",
      "+-----+----------------------------------------+----------+\n",
      "|label|probability                             |prediction|\n",
      "+-----+----------------------------------------+----------+\n",
      "|0    |[0.9816942623349085,0.01830573766509151]|0.0       |\n",
      "|0    |[0.8964592926384412,0.10354070736155883]|0.0       |\n",
      "|0    |[0.845914224595905,0.15408577540409504] |0.0       |\n",
      "|0    |[0.6812148102329231,0.318785189767077]  |0.0       |\n",
      "|0    |[0.6976636983246348,0.3023363016753652] |0.0       |\n",
      "|0    |[0.72433912351231,0.27566087648769]     |0.0       |\n",
      "|0    |[0.5730115632253174,0.4269884367746826] |0.0       |\n",
      "|0    |[0.9110588779715431,0.08894112202845691]|0.0       |\n",
      "|0    |[0.7748100240503034,0.22518997594969664]|0.0       |\n",
      "|0    |[0.7604404567342387,0.23955954326576148]|0.0       |\n",
      "|0    |[0.6265348876129152,0.37346511238708485]|0.0       |\n",
      "|0    |[0.42851410467895906,0.5714858953210409]|1.0       |\n",
      "|1    |[0.8361146054991377,0.1638853945008622] |0.0       |\n",
      "|1    |[0.7216438135593233,0.27835618644067667]|0.0       |\n",
      "|1    |[0.31825194059783907,0.6817480594021609]|1.0       |\n",
      "|1    |[0.5147551272145049,0.48524487278549516]|0.0       |\n",
      "|1    |[0.39581386471469837,0.6041861352853016]|1.0       |\n",
      "|1    |[0.7119506458737258,0.2880493541262742] |0.0       |\n",
      "|1    |[0.7092164541426221,0.2907835458573779] |0.0       |\n",
      "|1    |[0.9134955949622775,0.08650440503772248]|0.0       |\n",
      "+-----+----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "lr_test = LogisticRegressionModel.load('./lr')\n",
    "\n",
    "# Use a featurizer to use trained features from an existing model\n",
    "featurizer_test = dl.DeepImageFeaturizer(inputCol = \"image\", outputCol = \"features\", modelName = \"InceptionV3\")\n",
    "\n",
    "# Pipeline both entities\n",
    "p_lr_test = PipelineModel(stages=[featurizer_test, lr_test])\n",
    "\n",
    "# Test and evaluate\n",
    "tested_lr_test = p_lr_test.transform(testDF)\n",
    "evaluator_lr_test = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Logistic Regression Model: Test set accuracy = \" + str(evaluator_lr_test.evaluate(tested_lr_test.select(\"prediction\", \"label\"))))\n",
    "\n",
    "tested_lr_test.select(\"label\", \"probability\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "## Xception InceptionV3\n",
    "vectorizer = dl.DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName='InceptionV3')\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol = \"label\", featuresCol=\"features\", maxDepth = 3)\n",
    "\n",
    "dt_pipeline = Pipeline(stages=[vectorizer, dt])\n",
    "\n",
    "dt_pipeline_model = dt_pipeline.fit(trainDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n",
      "Decision Tree Model: Test set accuracy = 0.4583333333333333\n",
      "+-----+----------------------------------------+----------+\n",
      "|label|probability                             |prediction|\n",
      "+-----+----------------------------------------+----------+\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.6428571428571429,0.35714285714285715]|0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.0,1.0]                               |1.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[0.6428571428571429,0.35714285714285715]|0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "+-----+----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test and evaluate\n",
    "tested_dt_test = dt_pipeline_model.transform(testDF)\n",
    "evaluator_dt_test = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Decision Tree Model: Test set accuracy = \" + str(evaluator_dt_test.evaluate(tested_dt_test.select(\"prediction\", \"label\"))))\n",
    "\n",
    "tested_dt_test.select(\"label\", \"probability\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_4c84b908e99f56ec16b2\n"
     ]
    }
   ],
   "source": [
    "dtModel = dt_pipeline_model\n",
    "print(dtModel)  # summary only\n",
    "dtModel.stages[1].write().overwrite().save('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload DT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeModel\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "dt_test = DecisionTreeModel.load('./dt')\n",
    "\n",
    "# Use a featurizer to use trained features from an existing model\n",
    "featurizer_dt_test = dl.DeepImageFeaturizer(inputCol = \"image\", outputCol = \"features\", modelName = \"InceptionV3\")\n",
    "\n",
    "# Pipeline both entities\n",
    "pdt_test = PipelineModel(stages=[featurizer_dt_test, dt_test])\n",
    "\n",
    "# Test and evaluate\n",
    "tested_dt_test = pdt_test.transform(testDF)\n",
    "evaluator_dt_test = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator_test.evaluate(tested_dt_test.select(\"prediction\", \"label\"))))\n",
    "\n",
    "tested_dt_test.select(\"label\", \"probability\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "## Xception InceptionV3\n",
    "vectorizer = dl.DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName='InceptionV3')\n",
    "\n",
    "rf = RandomForestClassifier(labelCol = \"label\", featuresCol=\"features\")\n",
    "\n",
    "rf_pipeline = Pipeline(stages=[vectorizer, rf])\n",
    "\n",
    "rf_pipeline_model = rf_pipeline.fit(trainDF)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n",
      "Random Forest Model: Test set accuracy = 0.5416666666666666\n",
      "+-----+----------------------------------------+----------+\n",
      "|label|probability                             |prediction|\n",
      "+-----+----------------------------------------+----------+\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.6428571428571429,0.35714285714285715]|0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.0,1.0]                               |1.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[0.6428571428571429,0.35714285714285715]|0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "+-----+----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test and evaluate\n",
    "tested_rf_test = rf_pipeline_model.transform(testDF)\n",
    "evaluator_rf_test = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Random Forest Model: Test set accuracy = \" + str(evaluator_rf_test.evaluate(tested_rf_test.select(\"prediction\", \"label\"))))\n",
    "\n",
    "tested_dt_test.select(\"label\", \"probability\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "lr_test = LogisticRegressionModel.load('./lr')\n",
    "\n",
    "# Use a featurizer to use trained features from an existing model\n",
    "featurizer_test = dl.DeepImageFeaturizer(inputCol = \"image\", outputCol = \"features\", modelName = \"InceptionV3\")\n",
    "\n",
    "# Pipeline both entities\n",
    "p_test = PipelineModel(stages=[featurizer_test, lr_test])\n",
    "\n",
    "# Test and evaluate\n",
    "tested_df_test = p_test.transform(testDF)\n",
    "evaluator_test = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator_test.evaluate(tested_df_test.select(\"prediction\", \"label\"))))\n",
    "\n",
    "tested_df_test.select(\"label\", \"probability\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "## Xception InceptionV3\n",
    "vectorizer = dl.DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName='InceptionV3')\n",
    "\n",
    "gbt = GBTClassifier(maxIter=10)\n",
    "\n",
    "gbt_pipeline = Pipeline(stages=[vectorizer, gbt])\n",
    "\n",
    "gbt_pipeline_model = gbt_pipeline.fit(trainDF)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 376 variables.\n",
      "Converted 376 variables to const ops.\n",
      "INFO:tensorflow:Froze 0 variables.\n",
      "Converted 0 variables to const ops.\n",
      "GBT Model: Test set accuracy = 0.5\n",
      "+-----+----------------------------------------+----------+\n",
      "|label|probability                             |prediction|\n",
      "+-----+----------------------------------------+----------+\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.6428571428571429,0.35714285714285715]|0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|0    |[0.0,1.0]                               |1.0       |\n",
      "|0    |[1.0,0.0]                               |0.0       |\n",
      "|0    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[0.6428571428571429,0.35714285714285715]|0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "|1    |[0.02564102564102564,0.9743589743589743]|1.0       |\n",
      "|1    |[1.0,0.0]                               |0.0       |\n",
      "+-----+----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test and evaluate\n",
    "tested_gbt_test = gbt_pipeline_model.transform(testDF)\n",
    "evaluator_gbt_test = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"GBT Model: Test set accuracy = \" + str(evaluator_gbt_test.evaluate(tested_gbt_test.select(\"prediction\", \"label\"))))\n",
    "\n",
    "tested_dt_test.select(\"label\", \"probability\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------+----------+\n",
      "|label|probability                             |prediction|\n",
      "+-----+----------------------------------------+----------+\n",
      "|0    |[0.9213679929239009,0.07863200707609908]|0.0       |\n",
      "|0    |[0.9109990064336037,0.08900099356639635]|0.0       |\n",
      "|0    |[0.5690384687450698,0.4309615312549302] |0.0       |\n",
      "|0    |[0.917621369873649,0.08237863012635105] |0.0       |\n",
      "|0    |[0.9234198064833812,0.07658019351661882]|0.0       |\n",
      "|0    |[0.9341221756527827,0.06587782434721734]|0.0       |\n",
      "|0    |[0.08713896088954212,0.9128610391104579]|1.0       |\n",
      "|0    |[0.06587782434721742,0.9341221756527825]|1.0       |\n",
      "|0    |[0.07447446412813939,0.9255255358718606]|1.0       |\n",
      "|0    |[0.14395522502022787,0.8560447749797722]|1.0       |\n",
      "|0    |[0.9242239200928457,0.07577607990715429]|0.0       |\n",
      "|0    |[0.06587782434721742,0.9341221756527825]|1.0       |\n",
      "|1    |[0.9189007369184469,0.08109926308155313]|0.0       |\n",
      "|1    |[0.9141603725626289,0.08583962743737106]|0.0       |\n",
      "|1    |[0.8867207649255524,0.11327923507444759]|0.0       |\n",
      "|1    |[0.9242239200928457,0.07577607990715429]|0.0       |\n",
      "|1    |[0.08583962743737113,0.9141603725626288]|1.0       |\n",
      "|1    |[0.9341221756527827,0.06587782434721734]|0.0       |\n",
      "|1    |[0.06587782434721742,0.9341221756527825]|1.0       |\n",
      "|1    |[0.9141603725626289,0.08583962743737106]|0.0       |\n",
      "+-----+----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tested_gbt_test.select(\"label\", \"probability\", \"prediction\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 58.33%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "binaryevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "binary_rate = binaryevaluator.evaluate(prediction)*100\n",
    "print(\"accuracy: {}%\" .format(round(binary_rate,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KERAS - Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preetham/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/preetham/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionV3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
